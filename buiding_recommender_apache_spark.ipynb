{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# An on-line movie recommending service using Spark & Flask - Building the recommender"
      ],
      "metadata": {
        "id": "K1cztPfUofl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook explains how to use the MovieLens dataset to build a movie recommender using collaborative filtering with Spark's Alternating Least Saqures implementation. It is organised in two parts. The first one is about getting and parsing movies and ratings data into Spark RDDs. The second is about building and using the recommender and persisting it for later use in our on-line recommender system."
      ],
      "metadata": {
        "id": "5UnKBdMCokvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting and processing the data"
      ],
      "metadata": {
        "id": "CHEjqz6lorHO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### File Download"
      ],
      "metadata": {
        "id": "OSEmPIAloxMW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NBQvLwbriUhU"
      },
      "outputs": [],
      "source": [
        "complete_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest.zip'\n",
        "small_dataset_url = 'http://files.grouplens.org/datasets/movielens/ml-latest-small.zip'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_dataset_path = 'datasets/ml-latest-small.zip'\n",
        "complete_dataset_path = 'datasets/ml-latest.zip'\n",
        "\n",
        "import os\n",
        "if not os.path.exists('datasets'):\n",
        "    os.makedirs('datasets')\n",
        "\n",
        "datasets_path = os.path.join('..', 'datasets')"
      ],
      "metadata": {
        "id": "TmzGstsrim6C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "small_f = urllib.request.urlretrieve (small_dataset_url, small_dataset_path)\n",
        "complete_f = urllib.request.urlretrieve (complete_dataset_url, complete_dataset_path)"
      ],
      "metadata": {
        "id": "tyX_-m4UisIO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(small_dataset_path, \"r\") as z:\n",
        "    z.extractall(datasets_path)\n",
        "\n",
        "with zipfile.ZipFile(complete_dataset_path, \"r\") as z:\n",
        "    z.extractall(datasets_path)"
      ],
      "metadata": {
        "id": "rGXRxZjukAx8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading and parsing datasets"
      ],
      "metadata": {
        "id": "BTLr7B_7o3JZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDOHROWxkOeD",
        "outputId": "4c612a79-c811-4702-b915-6b76d6efe99f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824028 sha256=83eb3bfbd97df77e3d2799efb9ffcee79d149f6b6799feaebaaddcf786074fe8\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "  Attempting uninstall: py4j\n",
            "    Found existing installation: py4j 0.10.9.7\n",
            "    Uninstalling py4j-0.10.9.7:\n",
            "      Successfully uninstalled py4j-0.10.9.7\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\""
      ],
      "metadata": {
        "id": "k1zglkyhkYNr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.1.2/spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.2-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ],
      "metadata": {
        "id": "rgTj02GikdFu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.2-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "ILkItWySkjjH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "GBbXf7_-k5ZC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "\n",
        "sc = SparkContext.getOrCreate()\n",
        "\n",
        "if sc.master == \"local[*]\":\n",
        "    conf = SparkConf().setAppName(\"MovieLensALS\").setMaster(\"local[*]\").set(\"spark.driver.memory\", \"4g\").set(\"spark.driver.extraJavaOptions\", \"-Xss8M\")\n",
        "    sc.stop()\n",
        "    sc = SparkContext(conf=conf)"
      ],
      "metadata": {
        "id": "vRfiHiNgk-Cf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_ratings_file = os.path.join(datasets_path, 'ml-latest-small', 'ratings.csv')\n",
        "\n",
        "small_ratings_raw_data = sc.textFile(small_ratings_file)\n",
        "small_ratings_raw_data_header = small_ratings_raw_data.take(1)[0]"
      ],
      "metadata": {
        "id": "_SVo5FhmkGh-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_ratings_data = small_ratings_raw_data.filter(lambda line: line!=small_ratings_raw_data_header)\\\n",
        "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1],tokens[2])).cache()"
      ],
      "metadata": {
        "id": "zjKh090JlGof"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "small_ratings_data.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT0Jehj_lOj9",
        "outputId": "d56abf83-1d24-49a5-f3c0-4d5a6b1c7a22"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', '1', '4.0'), ('1', '3', '4.0'), ('1', '6', '4.0')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "small_movies_file = os.path.join(datasets_path, 'ml-latest-small', 'movies.csv')\n",
        "\n",
        "small_movies_raw_data = sc.textFile(small_movies_file)\n",
        "small_movies_raw_data_header = small_movies_raw_data.take(1)[0]\n",
        "\n",
        "small_movies_data = small_movies_raw_data.filter(lambda line: line!=small_movies_raw_data_header)\\\n",
        "    .map(lambda line: line.split(\",\")).map(lambda tokens: (tokens[0],tokens[1])).cache()\n",
        "    \n",
        "small_movies_data.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lF1sjPVnlR2w",
        "outputId": "d1ddeb19-6851-47ec-ad12-9226409443b6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('1', 'Toy Story (1995)'),\n",
              " ('2', 'Jumanji (1995)'),\n",
              " ('3', 'Grumpier Old Men (1995)')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collaborative Filtering"
      ],
      "metadata": {
        "id": "FSsY4W5mpFcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting ALS parameters using the small dataset"
      ],
      "metadata": {
        "id": "BddYC0glpMZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_RDD, validation_RDD, test_RDD = small_ratings_data.randomSplit([6, 2, 2], seed=0)\n",
        "validation_for_predict_RDD = validation_RDD.map(lambda x: (x[0], x[1]))\n",
        "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))"
      ],
      "metadata": {
        "id": "IULp2maYlWdN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.recommendation import ALS\n",
        "import math\n",
        "\n",
        "seed = 5\n",
        "# iteration using values 5, 10, and 20\n",
        "iterations = [5, 10, 20]\n",
        "regularization_parameter = 0.1\n",
        "ranks = [4, 8, 12]\n",
        "errors = [0] * 9\n",
        "err = 0\n",
        "tolerance = 0.02\n",
        "\n",
        "min_error = float('inf')\n",
        "best_rank = -1\n",
        "best_iteration = -1\n",
        "for rank in ranks:\n",
        "  # additional loop to combine rank and iteration\n",
        "  for iteration in iterations:\n",
        "    model = ALS.train(training_RDD, rank, seed=seed, iterations=iteration,\n",
        "                      lambda_=regularization_parameter)\n",
        "    predictions = model.predictAll(validation_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
        "    rates_and_preds = validation_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
        "    error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
        "    errors[err] = error\n",
        "    err += 1\n",
        "    print('For rank %s and iteration %s the RMSE is %s' % (rank, iteration, error))\n",
        "    if error < min_error:\n",
        "      min_error = error\n",
        "      best_rank = rank\n",
        "      best_iteration = iteration\n",
        "\n",
        "print('The best model was trained with rank %s and iteration %s' % (best_rank, best_iteration))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNCqNoFhllv8",
        "outputId": "05a418c3-44dd-4e7a-a325-c26656919aec"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For rank 4 and iteration 5 the RMSE is 0.9216828115540059\n",
            "For rank 4 and iteration 10 the RMSE is 0.9121002114021121\n",
            "For rank 4 and iteration 20 the RMSE is 0.9084344829867742\n",
            "For rank 8 and iteration 5 the RMSE is 0.9252257022633836\n",
            "For rank 8 and iteration 10 the RMSE is 0.9184327213070025\n",
            "For rank 8 and iteration 20 the RMSE is 0.9154033053129291\n",
            "For rank 12 and iteration 5 the RMSE is 0.9251850957336817\n",
            "For rank 12 and iteration 10 the RMSE is 0.9160151537868968\n",
            "For rank 12 and iteration 20 the RMSE is 0.9109898805756902\n",
            "The best model was trained with rank 4 and iteration 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uMBr_aIl7Wq",
        "outputId": "92806c82-8d78-490c-9738-fe62437f6a07"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((372, 1084), 3.6273558036170312),\n",
              " ((4, 1084), 3.806848948516306),\n",
              " ((402, 1084), 3.4207522972274793)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rates_and_preds.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IvAYKb7Jl-BE",
        "outputId": "7c0b39ec-ef9b-4447-ebc6-c8cf92e8407f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((1, 457), (5.0, 4.505973514879727)),\n",
              " ((1, 1025), (5.0, 4.598382643002677)),\n",
              " ((1, 1089), (5.0, 4.855986245944868))]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = ALS.train(training_RDD, best_rank, seed=seed, iterations=best_iteration,\n",
        "                      lambda_=regularization_parameter)\n",
        "predictions = model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
        "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
        "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
        "    \n",
        "print('For testing data the RMSE is %s' % (error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-0mYv_UmA7-",
        "outputId": "5f4f3c04-4caf-4367-a5af-c188c00d3e03"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For testing data the RMSE is 0.9098996087060645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using the complete dataset to build the final model"
      ],
      "metadata": {
        "id": "uo7gwIyIpTTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the complete dataset file\n",
        "complete_ratings_file = os.path.join(datasets_path, 'ml-latest', 'ratings.csv')\n",
        "complete_ratings_raw_data = sc.textFile(complete_ratings_file)\n",
        "complete_ratings_raw_data_header = complete_ratings_raw_data.take(1)[0]\n",
        "\n",
        "# Parse\n",
        "complete_ratings_data = complete_ratings_raw_data.filter(lambda line: line!=complete_ratings_raw_data_header)\\\n",
        "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n",
        "    \n",
        "print(\"There are %s recommendations in the complete dataset\" % (complete_ratings_data.count()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUltGLnwmHQF",
        "outputId": "8ed2c5d0-814d-4c1a-f0e4-b87b847cba83"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 27753444 recommendations in the complete dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_RDD, test_RDD = complete_ratings_data.randomSplit([7, 3], seed=0)\n",
        "\n",
        "complete_model = ALS.train(training_RDD, best_rank, seed=seed, \n",
        "                           iterations=best_iteration, lambda_=regularization_parameter)"
      ],
      "metadata": {
        "id": "jsIAmscRmOaF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_for_predict_RDD = test_RDD.map(lambda x: (x[0], x[1]))\n",
        "\n",
        "predictions = complete_model.predictAll(test_for_predict_RDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
        "rates_and_preds = test_RDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
        "error = math.sqrt(rates_and_preds.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
        "    \n",
        "print('For testing data the RMSE is %s' % (error))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPcsJzcSmRiz",
        "outputId": "6b0a172f-b2c4-4a41-d97e-0489142c4a89"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For testing data the RMSE is 0.8320316099023749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to make recommendations"
      ],
      "metadata": {
        "id": "z7HIz0IWpaIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "complete_movies_file = os.path.join(datasets_path, 'ml-latest', 'movies.csv')\n",
        "complete_movies_raw_data = sc.textFile(complete_movies_file)\n",
        "complete_movies_raw_data_header = complete_movies_raw_data.take(1)[0]\n",
        "\n",
        "# Parse\n",
        "complete_movies_data = complete_movies_raw_data.filter(lambda line: line!=complete_movies_raw_data_header)\\\n",
        "    .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n",
        "\n",
        "complete_movies_titles = complete_movies_data.map(lambda x: (int(x[0]),x[1]))\n",
        "    \n",
        "print(\"There are %s movies in the complete dataset\" % (complete_movies_titles.count()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7fE8Sa6mVcN",
        "outputId": "150c2a85-7436-480e-954d-6a7f6c094f93"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 58098 movies in the complete dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_counts_and_averages(ID_and_ratings_tuple):\n",
        "    nratings = len(ID_and_ratings_tuple[1])\n",
        "    return ID_and_ratings_tuple[0], (nratings, float(sum(x for x in ID_and_ratings_tuple[1]))/nratings)\n",
        "\n",
        "movie_ID_with_ratings_RDD = (complete_ratings_data.map(lambda x: (x[1], x[2])).groupByKey())\n",
        "movie_ID_with_avg_ratings_RDD = movie_ID_with_ratings_RDD.map(get_counts_and_averages)\n",
        "movie_rating_counts_RDD = movie_ID_with_avg_ratings_RDD.map(lambda x: (x[0], x[1][0]))"
      ],
      "metadata": {
        "id": "0m36tCLmmks7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adding new user ratings"
      ],
      "metadata": {
        "id": "6HbDjw7xpiCS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_user_ID = 0\n",
        "\n",
        "# The format of each line is (userID, movieID, rating)\n",
        "new_user_ratings = [\n",
        "     (0,260,9), # Star Wars (1977)\n",
        "     (0,1,8), # Toy Story (1995)\n",
        "     (0,16,7), # Casino (1995)\n",
        "     (0,25,8), # Leaving Las Vegas (1995)\n",
        "     (0,32,9), # Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
        "     (0,335,4), # Flintstones, The (1994)\n",
        "     (0,379,3), # Timecop (1994)\n",
        "     (0,296,7), # Pulp Fiction (1994)\n",
        "     (0,858,10) , # Godfather, The (1972)\n",
        "     (0,50,8) # Usual Suspects, The (1995)\n",
        "    ]\n",
        "new_user_ratings_RDD = sc.parallelize(new_user_ratings)\n",
        "print('New user ratings: %s' % new_user_ratings_RDD.take(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJM_gYGYnC-R",
        "outputId": "44d2abd2-3e24-43f7-9d1f-7df849dbb981"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New user ratings: [(0, 260, 9), (0, 1, 8), (0, 16, 7), (0, 25, 8), (0, 32, 9), (0, 335, 4), (0, 379, 3), (0, 296, 7), (0, 858, 10), (0, 50, 8)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "complete_data_with_new_ratings_RDD = complete_ratings_data.union(new_user_ratings_RDD)"
      ],
      "metadata": {
        "id": "bVd6gFfZpmex"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "\n",
        "t0 = time()\n",
        "new_ratings_model = ALS.train(complete_data_with_new_ratings_RDD, best_rank, seed=seed, \n",
        "                              iterations=best_iteration, lambda_=regularization_parameter)\n",
        "tt = time() - t0\n",
        "\n",
        "print(\"New model trained in %s seconds\" % round(tt,3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Maz4RNAvprkN",
        "outputId": "386f7176-0eca-4ed0-8b4f-520fb3debbea"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New model trained in 314.902 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting top recommendations"
      ],
      "metadata": {
        "id": "0Ed_ih9xpwn1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_user_ratings_ids = map(lambda x: x[1], new_user_ratings) # get just movie IDs\n",
        "# keep just those not on the ID list (thanks Lei Li for spotting the error!)\n",
        "new_user_unrated_movies_RDD = (complete_movies_data.filter(lambda x: x[0] not in new_user_ratings_ids).map(lambda x: (new_user_ID, x[0])))\n",
        "\n",
        "# Use the input RDD, new_user_unrated_movies_RDD, with new_ratings_model.predictAll() to predict new ratings for the movies\n",
        "new_user_recommendations_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)"
      ],
      "metadata": {
        "id": "h-OZiVvNpxzE"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform new_user_recommendations_RDD into pairs of the form (Movie ID, Predicted Rating)\n",
        "new_user_recommendations_rating_RDD = new_user_recommendations_RDD.map(lambda x: (x.product, x.rating))\n",
        "new_user_recommendations_rating_title_and_count_RDD = \\\n",
        "    new_user_recommendations_rating_RDD.join(complete_movies_titles).join(movie_rating_counts_RDD)\n",
        "new_user_recommendations_rating_title_and_count_RDD.take(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xuoz6Np5pzqa",
        "outputId": "4da2c953-c4f3-4af7-ca4b-aa91db3d307b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(6216,\n",
              "  ((7.026445662645672, 'Nowhere in Africa (Nirgendwo in Afrika) (2001)'),\n",
              "   717)),\n",
              " (124320, ((7.492523897937501, 'Once a Thief (1965)'), 1)),\n",
              " (83916, ((6.498638531131836, 'Blues in the Night (1941)'), 9))]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_user_recommendations_rating_title_and_count_RDD = \\\n",
        "    new_user_recommendations_rating_title_and_count_RDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))"
      ],
      "metadata": {
        "id": "nfi4SeYFp4Ke"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_movies = new_user_recommendations_rating_title_and_count_RDD.filter(lambda r: r[2]>=25).takeOrdered(25, key=lambda x: -x[1])\n",
        "\n",
        "print ('TOP recommended movies (with more than 25 reviews):\\n%s' %\n",
        "        '\\n'.join(map(str, top_movies)))"
      ],
      "metadata": {
        "id": "vde0mcmvp6Ru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c184cbba-7016-4c15-c416-3d1f71f34cb1"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TOP recommended movies (with more than 25 reviews):\n",
            "('Music for One Apartment and Six Drummers (2001)', 9.127790682513762, 31)\n",
            "('Rabbit of Seville (1950)', 8.981667585474511, 30)\n",
            "('\"Human Condition III', 8.924352265935553, 91)\n",
            "('Baseball (1994)', 8.825348145082458, 42)\n",
            "('Harakiri (Seppuku) (1962)', 8.82350612380764, 679)\n",
            "('Connections (1978)', 8.80328925260546, 49)\n",
            "('\"I', 8.761593869238741, 85)\n",
            "(\"Jim Henson's The Storyteller (1989)\", 8.737766561534556, 36)\n",
            "('Wow! A Talking Fish! (1983)', 8.733375962558078, 47)\n",
            "('\"Last Lions', 8.731667090276083, 38)\n",
            "('Duck Amuck (1953)', 8.720967892241077, 226)\n",
            "('Elway To Marino (2013)', 8.720128372049018, 25)\n",
            "('\"Lonely Wife', 8.71044688710834, 43)\n",
            "('Cosmos', 8.701890553829813, 157)\n",
            "('The Garden of Sinners - Chapter 5: Paradox Paradigm (2008)', 8.689368679793624, 27)\n",
            "('Rabbit Fire (1951)', 8.678015012489311, 46)\n",
            "('Dimensions of Dialogue (Moznosti dialogu) (1982)', 8.67314498984205, 65)\n",
            "('Crooks in Clover (a.k.a. Monsieur Gangster) (Les tontons flingueurs) (1963)', 8.666302841107914, 52)\n",
            "('\"In the blue sea', 8.661191712900077, 37)\n",
            "('\"Great War', 8.659008343795655, 31)\n",
            "('Seven Samurai (Shichinin no samurai) (1954)', 8.606794929069231, 14578)\n",
            "('\"Godfather', 8.604666177681054, 60904)\n",
            "('Ikiru (1952)', 8.601377373131328, 1551)\n",
            "('\"Century of the Self', 8.589141440685239, 213)\n",
            "('The War (2007)', 8.57146593019801, 53)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting individual ratings"
      ],
      "metadata": {
        "id": "DN_Eg0s5p98J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_movie = sc.parallelize([(0, 500)]) # Quiz Show (1994)\n",
        "individual_movie_rating_RDD = new_ratings_model.predictAll(new_user_unrated_movies_RDD)\n",
        "individual_movie_rating_RDD.take(1)"
      ],
      "metadata": {
        "id": "CDDsvsC5p9jT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cbc59d5-c8fc-4005-bf6e-396ba4e92ac2"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Rating(user=0, product=116688, rating=2.0178150675852966)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Persisting the model"
      ],
      "metadata": {
        "id": "-Dh5orxhqEWz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.mllib.recommendation import MatrixFactorizationModel\n",
        "\n",
        "model_path = os.path.join('..', 'models', 'movie_lens_als')\n",
        "\n",
        "# Save and load model\n",
        "model.save(sc, model_path)\n",
        "same_model = MatrixFactorizationModel.load(sc, model_path)"
      ],
      "metadata": {
        "id": "F2rNY-DZqH8T"
      },
      "execution_count": 37,
      "outputs": []
    }
  ]
}